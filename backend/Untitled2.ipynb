{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-21-c91030e0914b>:40: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  phone_dt_array = pd.Series()\n",
      "<ipython-input-21-c91030e0914b>:41: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  phone_d1_array = pd.Series()\n",
      "<ipython-input-21-c91030e0914b>:42: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  phone_d2_array = pd.Series()\n",
      "<ipython-input-21-c91030e0914b>:43: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  phone_d3_array = pd.Series()\n",
      "<ipython-input-21-c91030e0914b>:44: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  phone_d4_array = pd.Series()\n",
      "<ipython-input-21-c91030e0914b>:45: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  phone_d5_array = pd.Series()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import gc\n",
    "def createjson_adddis(dictcopy, original):\n",
    "   # print(dictcopy, original)\n",
    "   # print(original[0])\n",
    "    i=1\n",
    "    l=len(dictcopy)\n",
    "    if(l>len(original)):\n",
    "        l=len(original)\n",
    "    while(i<=l):\n",
    "        dictcopy[i]=original[i-1]\n",
    "        i+=1\n",
    "    dictcopy= pd.Series(dictcopy)\n",
    "    dictcopy=pd.DataFrame(dictcopy).reset_index()\n",
    "    dictcopy.columns=[\"index\", \"value\"]\n",
    "    dictcopya=dictcopy[\"value\"].copy()\n",
    "    dictcopya=pd.Series(dictcopya)\n",
    "   # print(dictcopy)\n",
    "    return dictcopy.to_json(orient='records'),dictcopya\n",
    "def createjson(dictcopy, original):\n",
    "   # print(dictcopy, original)\n",
    "   # print(original[0])\n",
    "    i=1\n",
    "    l=len(dictcopy)\n",
    "    if(l>len(original)):\n",
    "        l=len(original)\n",
    "    while(i<=l):\n",
    "        dictcopy[i]=original[i-1]\n",
    "        i+=1\n",
    "    dictcopy= pd.Series(dictcopy)\n",
    "    dictcopy=pd.DataFrame(dictcopy).reset_index()\n",
    "    dictcopy.columns=[\"index\", \"value\"]\n",
    "    dictcopya=dictcopy[\"value\"].copy()\n",
    "    dictcopya=pd.Series(dictcopya)\n",
    "   # print(dictcopy)\n",
    "    return dictcopy.to_json(orient='records'),dictcopya\n",
    "phone_dt_array = pd.Series() \n",
    "phone_d1_array = pd.Series() \n",
    "phone_d2_array = pd.Series() \n",
    "phone_d3_array = pd.Series() \n",
    "phone_d4_array = pd.Series() \n",
    "phone_d5_array = pd.Series() \n",
    "def createjsonYear_addis(phone_dt_dict, dt_phone):\n",
    "    i=0\n",
    "\n",
    "    df = pd.DataFrame(dt_phone)\n",
    "    while(i<len(dt_phone)):\n",
    "        phone_dt_dict[df.iloc[i]['Time']]+=1\n",
    "        i+=1\n",
    "    phone_dt_dict= pd.Series(phone_dt_dict)\n",
    "    phone_dt_dict=pd.DataFrame(phone_dt_dict).reset_index()\n",
    "    phone_dt_dict.columns=[\"index\", \"value\"]\n",
    "    phone_dt_dict1=phone_dt_dict[\"value\"].copy()\n",
    "    phone_dt_dict1=pd.Series(phone_dt_dict1)\n",
    "    return phone_dt_dict.to_json(orient='records'),phone_dt_dict1\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createjsontravel(minv, maxv,dt_travel):\n",
    "    travel_s_freq=list()\n",
    "    travel_d_freq=list()\n",
    "\n",
    "\n",
    "    travel_s_freq.append(len(dt_travel[(dt_travel['Time']>=minv)&(dt_travel['Time']<=maxv)&(dt_travel['SourceLocation']==0)]))\n",
    "    travel_s_freq.append(len(dt_travel[(dt_travel['Time']>=minv)&(dt_travel['Time']<=maxv)&(dt_travel['SourceLocation']==1)]))\n",
    "    travel_s_freq.append(len(dt_travel[(dt_travel['Time']>=minv)&(dt_travel['Time']<=maxv)&(dt_travel['SourceLocation']==2)]))\n",
    "    travel_s_freq.append(len(dt_travel[(dt_travel['Time']>=minv)&(dt_travel['Time']<=maxv)&(dt_travel['SourceLocation']==3)]))\n",
    "    travel_s_freq.append(len(dt_travel[(dt_travel['Time']>=minv)&(dt_travel['Time']<=maxv)&(dt_travel['SourceLocation']==4)]))\n",
    "    travel_s_freq.append(len(dt_travel[(dt_travel['Time']>=minv)&(dt_travel['Time']<=maxv)&(dt_travel['SourceLocation']==5)]))\n",
    "    travel_s_arr=travel_s_freq.copy()\n",
    "    travel_s_freq=pd.DataFrame(travel_s_freq)\n",
    "    travel_s_freq.columns=[\"value\"]\n",
    "    travel_s_freq[\"index\"]=[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\"]\n",
    "    travel_s_freq=travel_s_freq.to_json(orient='records')\n",
    "\n",
    "    travel_d_freq.append(len(dt_travel[(dt_travel['Time']>=minv)&(dt_travel['Time']<=maxv)&(dt_travel['TargetLocation']==0)]))\n",
    "    travel_d_freq.append(len(dt_travel[(dt_travel['Time']>=minv)&(dt_travel['Time']<=maxv)&(dt_travel['TargetLocation']==1)]))\n",
    "    travel_d_freq.append(len(dt_travel[(dt_travel['Time']>=minv)&(dt_travel['Time']<=maxv)&(dt_travel['TargetLocation']==2)]))\n",
    "    travel_d_freq.append(len(dt_travel[(dt_travel['Time']>=minv)&(dt_travel['Time']<=maxv)&(dt_travel['TargetLocation']==3)]))\n",
    "    travel_d_freq.append(len(dt_travel[(dt_travel['Time']>=minv)&(dt_travel['Time']<=maxv)&(dt_travel['TargetLocation']==4)]))\n",
    "    travel_d_freq.append(len(dt_travel[(dt_travel['Time']>=minv)&(dt_travel['Time']<=maxv)&(dt_travel['TargetLocation']==5)]))\n",
    "    travel_d_arr=travel_d_freq.copy()\n",
    "    travel_d_freq=pd.DataFrame(travel_d_freq)\n",
    "    travel_d_freq.columns=[\"value\"]\n",
    "    travel_d_freq[\"index\"]=[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\"]\n",
    "    travel_d_freq=travel_d_freq.to_json(orient='records')\n",
    "    l=len(dt_travel[(dt_travel['Time']>=minv)&(dt_travel['Time']<=maxv)])\n",
    "    t=sum(dt_travel[(dt_travel['Time']>=minv)&(dt_travel['Time']<=maxv)]['Weight'])\n",
    "    re=0\n",
    "    if(l!=0):\n",
    "      re=t/l\n",
    "    return travel_s_freq,travel_d_freq,round(re,3),travel_s_arr,travel_d_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "def normalize(df):\n",
    "    result = df.copy()\n",
    "    result.iloc[:,:] = Normalizer(norm='l1').fit_transform(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dt reading finished \n",
      "d1 reading finished \n",
      "d2 reading finished \n",
      "d3 reading finished \n",
      "d4 reading finished \n",
      "dt_phone cut finished \n",
      "d1_phone cut finished \n",
      "d2_phone cut finished \n",
      "d3_phone cut finished \n",
      "d4_phone cut finished \n",
      "d5_phone cut finished \n",
      "Garbage collector: collected 1958 objects.\n",
      "      graph1    graph2    graph3    graph4    graph5                index\n",
      "0   0.144079  0.090349  0.241762  0.236873  0.286937           phone call\n",
      "1   0.143018  0.112543  0.232121  0.236816  0.275502        phone receive\n",
      "2   0.143681  0.099778  0.241242  0.228825  0.286475  phone communication\n",
      "3   0.129454  0.078492  0.208974  0.280330  0.302750           email send\n",
      "4   0.138069  0.069035  0.208122  0.283249  0.301526        email receive\n",
      "5   0.131172  0.072371  0.211836  0.277799  0.306822  email communication\n",
      "6   0.153846  0.153846  0.230769  0.307692  0.153846     procurement freq\n",
      "7   0.079784  0.070663  0.208880  0.015436  0.625238   procurement weight\n",
      "8   0.100959  0.155668  0.131416  0.259165  0.352792    demographics freq\n",
      "9   0.081079  0.151359  0.081079  0.340533  0.345949  demographics weight\n",
      "10  0.082872  0.154705  0.082872  0.348062  0.331488      source location\n",
      "11  0.133162  0.113406  0.156357  0.177832  0.419243      target location\n",
      "12  0.363480  0.191796  0.167796  0.057768  0.219160            trip time\n",
      "0 1 0 0 0\n",
      "0 2 0 0 0\n",
      "0 3 0 0 0\n",
      "0 4 0 0 0\n",
      "0 5 0 0 0\n",
      "0 6 0 0 0\n",
      "1 7 0 0 1\n",
      "1 7 0 1 1\n",
      "2 7 0 1 1\n",
      "3 7 1 1 1\n",
      "4 7 2 1 1\n",
      "4 8 2 1 1\n",
      "4 8 2 2 1\n",
      "   value   index\n",
      "0      4  graph1\n",
      "1      8  graph2\n",
      "2      2  graph3\n",
      "3      2  graph4\n",
      "4      1  graph5\n"
     ]
    }
   ],
   "source": [
    "def analysis():\n",
    "    path='./data/'\n",
    "    minv=0\n",
    "    maxv=365\n",
    "    gr1=list()\n",
    "    gr2=list()\n",
    "    gr3=list()\n",
    "    gr4=list()\n",
    "    gr5=list()\n",
    "    dt=pd.read_csv(path+'CGCS-Template.csv', delimiter = ',')\n",
    "    dt['Time']=np.floor(dt['Time']/86400).astype(int)\n",
    "    print(\"dt reading finished \")\n",
    "\n",
    "    d1=pd.read_csv(path+'Q1-Graph1.csv', delimiter = ',')\n",
    "    d1['Time']=np.floor(d1['Time']/86400).astype(int)\n",
    "    print(\"d1 reading finished \")\n",
    "\n",
    "    d2=pd.read_csv(path+'Q1-Graph2.csv', delimiter = ',')\n",
    "    d2['Time']=np.floor(d2['Time']/86400).astype(int)\n",
    "    print(\"d2 reading finished \")\n",
    "\n",
    "    d3=pd.read_csv(path+'Q1-Graph3.csv', delimiter = ',')\n",
    "    d3['Time']=np.floor(d3['Time']/86400).astype(int)\n",
    "    print(\"d3 reading finished \")\n",
    "\n",
    "    d4=pd.read_csv(path+'Q1-Graph4.csv', delimiter = ',')\n",
    "    d4['Time']=np.floor(d4['Time']/86400).astype(int)\n",
    "    print(\"d4 reading finished \")\n",
    "\n",
    "    d5=pd.read_csv(path+'Q1-Graph5.csv', delimiter = ',')\n",
    "    d5['Time']=np.floor(d5['Time']/86400).astype(int)\n",
    "    dt_phone=dt[dt['eType']==1]\n",
    "    print(\"dt_phone cut finished \")\n",
    "\n",
    "\n",
    "    d1_phone=d1[d1['eType']==1]\n",
    "    print(\"d1_phone cut finished \")\n",
    "\n",
    "\n",
    "    d2_phone=d2[d2['eType']==1]\n",
    "    print(\"d2_phone cut finished \")\n",
    "\n",
    "\n",
    "    d3_phone=d3[d3['eType']==1]\n",
    "    print(\"d3_phone cut finished \")\n",
    "\n",
    "\n",
    "    d4_phone=d4[d4['eType']==1]\n",
    "    print(\"d4_phone cut finished \")\n",
    "\n",
    "\n",
    "    d5_phone=d5[d5['eType']==1]\n",
    "    print(\"d5_phone cut finished \")\n",
    "    phone_s_length=len(dt_phone['Source'].value_counts())\n",
    " \n",
    "    i=1\n",
    "    phone_s_dict=dict()\n",
    "    while(i<=phone_s_length):\n",
    "        phone_s_dict[i]=0    \n",
    "        i+=1\n",
    "    phone_s_dict=pd.Series(phone_s_dict) \n",
    "    \n",
    "    phone_t_length=len(dt_phone['Target'].value_counts())\n",
    "   \n",
    "    i=1\n",
    "    phone_t_dict=dict()\n",
    "    while(i<=phone_t_length):\n",
    "        phone_t_dict[i]=0    \n",
    "        i+=1\n",
    "    phone_t_dict=pd.Series(phone_t_dict) \n",
    "\n",
    "    i=1\n",
    "    phone_year_dict=dict()\n",
    "    while(i<=365):\n",
    "        phone_year_dict[i]=0    \n",
    "        i+=1\n",
    "    phone_year_dict=pd.Series(phone_year_dict) \n",
    "    dt_rs=dt_phone['Source'][(dt_phone['Time']>=minv)&(dt_phone['Time']<=maxv)].value_counts().values\n",
    "    d1_rs=d1_phone['Source'][(d1_phone['Time']>=minv)&(d1_phone['Time']<=maxv)].value_counts().values\n",
    "    d2_rs=d2_phone['Source'][(d2_phone['Time']>=minv)&(d2_phone['Time']<=maxv)].value_counts().values\n",
    "    d3_rs=d3_phone['Source'][(d3_phone['Time']>=minv)&(d3_phone['Time']<=maxv)].value_counts().values\n",
    "    d4_rs=d4_phone['Source'][(d4_phone['Time']>=minv)&(d4_phone['Time']<=maxv)].value_counts().values\n",
    "    d5_rs=d5_phone['Source'][(d5_phone['Time']>=minv)&(d5_phone['Time']<=maxv)].value_counts().values\n",
    "\n",
    "   # print(dt_rs,d1_rs,d2_rs,d3_rs,d4_rs,d5_rs)\n",
    "\n",
    "    dt_rs1=phone_s_dict.copy()\n",
    "  #  dt_rsnew=compute.createjson(dt_rs1,dt_rs)\n",
    "\n",
    "    d1_rs1=phone_s_dict.copy()\n",
    "   # d1_rsnew=compute.createjson(d1_rs1,d1_rs)\n",
    "\n",
    "    d2_rs1=phone_s_dict.copy()\n",
    "  #  d2_rsnew=compute.createjson(d2_rs1,d2_rs)\n",
    "\n",
    "    d3_rs1=phone_s_dict.copy()\n",
    "  #  d3_rsnew=compute.createjson(d3_rs1,d3_rs)\n",
    "\n",
    "    d4_rs1=phone_s_dict.copy()\n",
    "  #  d4_rsnew=compute.createjson(d4_rs1,d4_rs)\n",
    "\n",
    "    d5_rs1=phone_s_dict.copy()\n",
    "  #  d5_rsnew=compute.createjson(d5_rs1,d5_rs)\n",
    "\n",
    "    \n",
    "    \n",
    "    dt_rsnew,dtarray=createjson_adddis(dt_rs1,dt_rs)\n",
    "   # print(dtarray)\n",
    "\n",
    " \n",
    "    d1_rsnew,d1array=createjson_adddis(d1_rs1,d1_rs)\n",
    "\n",
    "\n",
    "    d2_rsnew,d2array=createjson_adddis(d2_rs1,d2_rs)\n",
    "\n",
    "\n",
    "    d3_rsnew,d3array=createjson_adddis(d3_rs1,d3_rs)\n",
    "\n",
    "   \n",
    "    d4_rsnew,d4array=createjson_adddis(d4_rs1,d4_rs)\n",
    "\n",
    "    \n",
    "    d5_rsnew,d5array=createjson_adddis(d5_rs1,d5_rs)\n",
    "    result=list()\n",
    "    result.append(round(stats.wasserstein_distance(dtarray,d1array),3))\n",
    "    result.append(round(stats.wasserstein_distance(dtarray,d2array),3))\n",
    "    result.append(round(stats.wasserstein_distance(dtarray,d3array),3))\n",
    "    result.append(round(stats.wasserstein_distance(dtarray,d4array),3))\n",
    "    result.append(round(stats.wasserstein_distance(dtarray,d5array),3))\n",
    "    gr1.append(round(stats.wasserstein_distance(dtarray,d1array),3))\n",
    "    gr2.append(round(stats.wasserstein_distance(dtarray,d2array),3))\n",
    "    gr3.append(round(stats.wasserstein_distance(dtarray,d3array),3))\n",
    "    gr4.append(round(stats.wasserstein_distance(dtarray,d4array),3))\n",
    "    gr5.append(round(stats.wasserstein_distance(dtarray,d5array),3))\n",
    "\n",
    "\n",
    "    dt_rt=dt_phone['Target'][(dt_phone['Time']>=minv)&(dt_phone['Time']<=maxv)].value_counts().values\n",
    "    d1_rt=d1_phone['Target'][(d1_phone['Time']>=minv)&(d1_phone['Time']<=maxv)].value_counts().values\n",
    "    d2_rt=d2_phone['Target'][(d2_phone['Time']>=minv)&(d2_phone['Time']<=maxv)].value_counts().values\n",
    "    d3_rt=d3_phone['Target'][(d3_phone['Time']>=minv)&(d3_phone['Time']<=maxv)].value_counts().values\n",
    "    d4_rt=d4_phone['Target'][(d4_phone['Time']>=minv)&(d4_phone['Time']<=maxv)].value_counts().values\n",
    "    d5_rt=d5_phone['Target'][(d5_phone['Time']>=minv)&(d5_phone['Time']<=maxv)].value_counts().values\n",
    "    dt_rt1=phone_t_dict.copy()\n",
    "    dt_rtnew=createjson(dt_rt1,dt_rt)\n",
    "\n",
    "    d1_rt1=phone_t_dict.copy()\n",
    "  #  d1_rtnew=compute.createjson(d1_rt1,d1_rt)\n",
    "\n",
    "    d2_rt1=phone_t_dict.copy()\n",
    "  #  d2_rtnew=compute.createjson(d2_rt1,d2_rt)\n",
    "\n",
    "    d3_rt1=phone_t_dict.copy()\n",
    "   # d3_rtnew=compute.createjson(d3_rt1,d3_rt)\n",
    "\n",
    "    d4_rt1=phone_t_dict.copy()\n",
    "   # d4_rtnew=compute.createjson(d4_rt1,d4_rt)\n",
    "\n",
    "    d5_rt1=phone_t_dict.copy()\n",
    "    #d5_rtnew=compute.createjson(d5_rt1,d5_rt)\n",
    "\n",
    "    dt_rtnew,dtarraynew=createjson_adddis(dt_rt1,dt_rt)\n",
    "\n",
    "  \n",
    "    d1_rtnew,d1arraynew=createjson_adddis(d1_rt1,d1_rt)\n",
    "\n",
    "  \n",
    "    d2_rtnew,d2arraynew=createjson_adddis(d2_rt1,d2_rt)\n",
    "\n",
    "\n",
    "    d3_rtnew,d3arraynew=createjson_adddis(d3_rt1,d3_rt)\n",
    "\n",
    "    d4_rtnew,d4arraynew=createjson_adddis(d4_rt1,d4_rt)\n",
    "\n",
    "  \n",
    "    d5_rtnew,d5arraynew=createjson_adddis(d5_rt1,d5_rt)\n",
    "    result.append(round(stats.wasserstein_distance(dtarraynew,d1arraynew),3))\n",
    "    result.append(round(stats.wasserstein_distance(dtarraynew,d2arraynew),3))\n",
    "    result.append(round(stats.wasserstein_distance(dtarraynew,d3arraynew),3))\n",
    "    result.append(round(stats.wasserstein_distance(dtarraynew,d4arraynew),3))\n",
    "    result.append(round(stats.wasserstein_distance(dtarraynew,d5arraynew),3)) \n",
    "    gr1.append(round(stats.wasserstein_distance(dtarraynew,d1arraynew),3))\n",
    "    gr2.append(round(stats.wasserstein_distance(dtarraynew,d2arraynew),3))\n",
    "    gr3.append(round(stats.wasserstein_distance(dtarraynew,d3arraynew),3))\n",
    "    gr4.append(round(stats.wasserstein_distance(dtarraynew,d4arraynew),3))\n",
    "    gr5.append(round(stats.wasserstein_distance(dtarraynew,d5arraynew),3)) \n",
    "    \n",
    "    if(minv==0):\n",
    "     minv=0\n",
    "    else :\n",
    "     minv=minv-1\n",
    "  #  print(len(email_dt_array[minv:(maxv-1)]))\n",
    "  #  print(len(email_dt_array))\n",
    "   # global phone_dt_array\n",
    "   # global phone_d1_array\n",
    "   # global phone_d2_array\n",
    "   # global phone_d3_array\n",
    "   # global phone_d4_array\n",
    "   # global phone_d5_array \n",
    "    \n",
    "    phone_dt_dict=phone_year_dict.copy()\n",
    "\n",
    "    phone_dt_dictnew,arr=createjsonYear_addis(phone_dt_dict, dt_phone)\n",
    "    phone_dt_array=arr\n",
    "    phone_d1_dict=phone_year_dict.copy()\n",
    "\n",
    "    phone_d1_dictnew,arr1=createjsonYear_addis(phone_d1_dict, d1_phone)\n",
    "    phone_d1_array=arr1\n",
    "    phone_d2_dict=phone_year_dict.copy()\n",
    "\n",
    "    phone_d2_dictnew,arr2=createjsonYear_addis(phone_d2_dict, d2_phone)\n",
    "    phone_d2_array=arr2\n",
    "    phone_d3_dict=phone_year_dict.copy()\n",
    "\n",
    "    phone_d3_dictnew,arr3=createjsonYear_addis(phone_d3_dict, d3_phone)\n",
    "    phone_d3_array=arr3\n",
    "    phone_d4_dict=phone_year_dict.copy()\n",
    "\n",
    "    phone_d4_dictnew,arr4=createjsonYear_addis(phone_d4_dict, d4_phone)\n",
    "    phone_d4_array=arr4\n",
    "    phone_d5_dict=phone_year_dict.copy()\n",
    "    \n",
    "    phone_d5_dictnew,arr5=createjsonYear_addis(phone_d5_dict, d5_phone)\n",
    "    phone_d5_array=arr5\n",
    "    result.append(round(stats.wasserstein_distance(phone_dt_array[minv:(maxv-1)],phone_d1_array[minv:(maxv-1)]),3))\n",
    "    result.append(round(stats.wasserstein_distance(phone_dt_array[minv:(maxv-1)],phone_d2_array[minv:(maxv-1)]),3))\n",
    "    result.append(round(stats.wasserstein_distance(phone_dt_array[minv:(maxv-1)],phone_d3_array[minv:(maxv-1)]),3))\n",
    "    result.append(round(stats.wasserstein_distance(phone_dt_array[minv:(maxv-1)],phone_d4_array[minv:(maxv-1)]),3))\n",
    "    result.append(round(stats.wasserstein_distance(phone_dt_array[minv:(maxv-1)],phone_d5_array[minv:(maxv-1)]),3))\n",
    "\n",
    "    gr1.append(round(stats.wasserstein_distance(phone_dt_array[minv:(maxv-1)],phone_d1_array[minv:(maxv-1)]),3))\n",
    "    gr2.append(round(stats.wasserstein_distance(phone_dt_array[minv:(maxv-1)],phone_d2_array[minv:(maxv-1)]),3))\n",
    "    gr3.append(round(stats.wasserstein_distance(phone_dt_array[minv:(maxv-1)],phone_d3_array[minv:(maxv-1)]),3))\n",
    "    gr4.append(round(stats.wasserstein_distance(phone_dt_array[minv:(maxv-1)],phone_d4_array[minv:(maxv-1)]),3))\n",
    "    gr5.append(round(stats.wasserstein_distance(phone_dt_array[minv:(maxv-1)],phone_d5_array[minv:(maxv-1)]),3))\n",
    "    \n",
    "    \n",
    "    result=pd.Series(result)  \n",
    "    collected = gc.collect() \n",
    "   \n",
    "# Prints Garbage collector  \n",
    "# as 0 object \n",
    "    print(\"Garbage collector: collected\", \n",
    "          \"%d objects.\" % collected)\n",
    "  #  print(result)\n",
    "    \n",
    "    \n",
    "    dt_email=dt[dt['eType']==0]\n",
    "   # print(\"dt_email cut finished \")\n",
    "\n",
    "    d1_email=d1[d1['eType']==0]\n",
    "   # print(\"d1_email cut finished \")\n",
    "\n",
    "    d2_email=d2[d2['eType']==0]\n",
    "  #  print(\"d2_email cut finished \")\n",
    "\n",
    "    d3_email=d3[d3['eType']==0]\n",
    "  #  print(\"d3_email cut finished \")\n",
    "\n",
    "    d4_email=d4[d4['eType']==0]\n",
    "   # print(\"d4_email cut finished \")\n",
    "\n",
    "    d5_email=d5[d5['eType']==0]\n",
    "   # print(\"d5_email cut finished \")    \n",
    "  #  return dt_email,d1_email,d2_email,d3_email,d4_email,d5_email\n",
    "    email_s_length=len(dt_email['Source'].value_counts())\n",
    " \n",
    "    i=1\n",
    "    email_s_dict=dict()\n",
    "    while(i<=email_s_length):\n",
    "        email_s_dict[i]=0    \n",
    "        i+=1\n",
    "    email_s_dict=pd.Series(email_s_dict) \n",
    "    \n",
    "    email_t_length=len(dt_email['Target'].value_counts())\n",
    "   \n",
    "    i=1\n",
    "    email_t_dict=dict()\n",
    "    while(i<=email_t_length):\n",
    "        email_t_dict[i]=0    \n",
    "        i+=1\n",
    "    email_t_dict=pd.Series(email_t_dict) \n",
    "    \n",
    "    i=1\n",
    "    email_year_dict=dict()\n",
    "    while(i<=365):\n",
    "        email_year_dict[i]=0    \n",
    "        i+=1\n",
    "    email_year_dict=pd.Series(email_year_dict)\n",
    "    dt_rs=dt_email['Source'].value_counts().values\n",
    "    d1_rs=d1_email['Source'].value_counts().values\n",
    "    d2_rs=d2_email['Source'].value_counts().values\n",
    "    d3_rs=d3_email['Source'].value_counts().values\n",
    "    d4_rs=d4_email['Source'].value_counts().values\n",
    "    d5_rs=d5_email['Source'].value_counts().values\n",
    "\n",
    "    #print(dt_rs,d1_rs,d2_rs,d3_rs,d4_rs,d5_rs)\n",
    "\n",
    "    dt_rs1=email_s_dict.copy()\n",
    "    dt_rsnew,dtarray=createjson(dt_rs1,dt_rs)\n",
    "\n",
    "    d1_rs1=email_s_dict.copy()\n",
    "    d1_rsnew,d1array=createjson(d1_rs1,d1_rs)\n",
    "\n",
    "    d2_rs1=email_s_dict.copy()\n",
    "    d2_rsnew,d2array=createjson(d2_rs1,d2_rs)\n",
    "\n",
    "    d3_rs1=email_s_dict.copy()\n",
    "    d3_rsnew,d3array=createjson(d3_rs1,d3_rs)\n",
    "\n",
    "    d4_rs1=email_s_dict.copy()\n",
    "    d4_rsnew,d4array=createjson(d4_rs1,d4_rs)\n",
    "\n",
    "    d5_rs1=email_s_dict.copy()\n",
    "    d5_rsnew,d5array=createjson(d5_rs1,d5_rs)\n",
    "\n",
    "    result=list()\n",
    "    result.append(round(stats.wasserstein_distance(dtarray,d1array),3))\n",
    "    result.append(round(stats.wasserstein_distance(dtarray,d2array),3))\n",
    "    result.append(round(stats.wasserstein_distance(dtarray,d3array),3))\n",
    "    result.append(round(stats.wasserstein_distance(dtarray,d4array),3))\n",
    "    result.append(round(stats.wasserstein_distance(dtarray,d5array),3))\n",
    "    \n",
    "    gr1.append(round(stats.wasserstein_distance(dtarray,d1array),3))\n",
    "    gr2.append(round(stats.wasserstein_distance(dtarray,d2array),3))\n",
    "    gr3.append(round(stats.wasserstein_distance(dtarray,d3array),3))\n",
    "    gr4.append(round(stats.wasserstein_distance(dtarray,d4array),3))\n",
    "    gr5.append(round(stats.wasserstein_distance(dtarray,d5array),3))\n",
    "\n",
    "    dt_rt=dt_email['Target'].value_counts().values\n",
    "    d1_rt=d1_email['Target'].value_counts().values\n",
    "    d2_rt=d2_email['Target'].value_counts().values\n",
    "    d3_rt=d3_email['Target'].value_counts().values\n",
    "    d4_rt=d4_email['Target'].value_counts().values\n",
    "    d5_rt=d5_email['Target'].value_counts().values\n",
    "    dt_rt1=email_t_dict.copy()\n",
    "    dt_rtnew,dtarraynew=createjson(dt_rt1,dt_rt)\n",
    "\n",
    "    d1_rt1=email_t_dict.copy()\n",
    "    d1_rtnew,d1arraynew=createjson(d1_rt1,d1_rt)\n",
    "\n",
    "    d2_rt1=email_t_dict.copy()\n",
    "    d2_rtnew,d2arraynew=createjson(d2_rt1,d2_rt)\n",
    "\n",
    "    d3_rt1=email_t_dict.copy()\n",
    "    d3_rtnew,d3arraynew=createjson(d3_rt1,d3_rt)\n",
    "\n",
    "    d4_rt1=email_t_dict.copy()\n",
    "    d4_rtnew,d4arraynew=createjson(d4_rt1,d4_rt)\n",
    "\n",
    "    d5_rt1=email_t_dict.copy()\n",
    "    d5_rtnew,d5arraynew=createjson(d5_rt1,d5_rt)\n",
    "    \n",
    "\n",
    "\n",
    "    result.append(round(stats.wasserstein_distance(dtarraynew,d1arraynew),3))\n",
    "    result.append(round(stats.wasserstein_distance(dtarraynew,d2arraynew),3))\n",
    "    result.append(round(stats.wasserstein_distance(dtarraynew,d3arraynew),3))\n",
    "    result.append(round(stats.wasserstein_distance(dtarraynew,d4arraynew),3))\n",
    "    result.append(round(stats.wasserstein_distance(dtarraynew,d5arraynew),3))\n",
    "\n",
    "    gr1.append(round(stats.wasserstein_distance(dtarraynew,d1arraynew),3))\n",
    "    gr2.append(round(stats.wasserstein_distance(dtarraynew,d2arraynew),3))\n",
    "    gr3.append(round(stats.wasserstein_distance(dtarraynew,d3arraynew),3))\n",
    "    gr4.append(round(stats.wasserstein_distance(dtarraynew,d4arraynew),3))\n",
    "    gr5.append(round(stats.wasserstein_distance(dtarraynew,d5arraynew),3))\n",
    "    \n",
    "    email_dt_dict=email_year_dict.copy()\n",
    "\n",
    "    email_dt_dictnew,arr=createjsonYear_addis(email_dt_dict, dt_email)\n",
    "    \n",
    "    global email_dt_array\n",
    "    global email_d1_array\n",
    "    global email_d2_array\n",
    "    global email_d3_array\n",
    "    global email_d4_array\n",
    "    global email_d5_array\n",
    "    email_dt_array=arr\n",
    "    \n",
    "    \n",
    "    email_d1_dict=email_year_dict.copy()\n",
    "\n",
    "    email_d1_dictnew,arr1=createjsonYear_addis(email_d1_dict, d1_email)\n",
    "    email_d1_array=arr1\n",
    "    email_d2_dict=email_year_dict.copy()\n",
    "\n",
    "    email_d2_dictnew,arr2=createjsonYear_addis(email_d2_dict, d2_email)\n",
    "    email_d2_array=arr2\n",
    "    email_d3_dict=email_year_dict.copy()\n",
    "\n",
    "    email_d3_dictnew,arr3=createjsonYear_addis(email_d3_dict, d3_email)\n",
    "    email_d3_array=arr3\n",
    "    email_d4_dict=email_year_dict.copy()\n",
    "\n",
    "    email_d4_dictnew,arr4=createjsonYear_addis(email_d4_dict, d4_email)\n",
    "    email_d4_array=arr4\n",
    "    email_d5_dict=email_year_dict.copy()\n",
    "\n",
    "    email_d5_dictnew,arr5=createjsonYear_addis(email_d5_dict, d5_email)\n",
    "    email_d5_array=arr5\n",
    "   # print(\"email finish analysis\")\n",
    "    #print(len(email_dt_array),len(email_d1_array),round(stats.wasserstein_distance(email_dt_array,email_d1_array),3))\n",
    "    result.append(round(stats.wasserstein_distance(email_dt_array,email_d1_array),3))\n",
    "    result.append(round(stats.wasserstein_distance(email_dt_array,email_d2_array),3))\n",
    "    result.append(round(stats.wasserstein_distance(email_dt_array,email_d3_array),3))\n",
    "    result.append(round(stats.wasserstein_distance(email_dt_array,email_d4_array),3))\n",
    "    result.append(round(stats.wasserstein_distance(email_dt_array,email_d5_array),3))\n",
    "    \n",
    "    gr1.append(round(stats.wasserstein_distance(email_dt_array,email_d1_array),3))\n",
    "    gr2.append(round(stats.wasserstein_distance(email_dt_array,email_d2_array),3))\n",
    "    gr3.append(round(stats.wasserstein_distance(email_dt_array,email_d3_array),3))\n",
    "    gr4.append(round(stats.wasserstein_distance(email_dt_array,email_d4_array),3))\n",
    "    gr5.append(round(stats.wasserstein_distance(email_dt_array,email_d5_array),3))\n",
    "    \n",
    "    result=pd.Series(result)\n",
    "  #  print(result)\n",
    "    dt_procu=dt[dt['eType']==2]\n",
    "  #  print(\"dt_procu cut finished \")\n",
    "\n",
    "\n",
    "    d1_procu=d1[d1['eType']==2]\n",
    "  #  print(\"d1_procu cut finished \")\n",
    "\n",
    "\n",
    "    d2_procu=d2[d2['eType']==2]\n",
    "  #  print(\"d2_procu cut finished \")\n",
    "\n",
    "\n",
    "    d3_procu=d3[d3['eType']==2]\n",
    "  #  print(\"d3_procu cut finished \")\n",
    "\n",
    "\n",
    "    d4_procu=d4[d4['eType']==2]\n",
    "  #  print(\"d4_procu cut finished \")\n",
    "\n",
    "\n",
    "    d5_procu=d5[d5['eType']==2]\n",
    "  #  print(\"d5_procu cut finished \")\n",
    "    \n",
    "\n",
    "   \n",
    "\n",
    "    procu_dict=[{\"template\":0},{\"graph1\":0},{\"graph2\":0},{\"graph3\":0},{\"graph4\":0},{\"graph5\":0}]\n",
    "\n",
    "    procu_dict=pd.Series(procu_dict) \n",
    "    procu_freq=list()\n",
    "    procu_freq.append(len(dt_procu[(dt_procu['Time']>=minv)&(dt_procu['Time']<=maxv)]))\n",
    "    procu_freq.append(len(d1_procu[(d1_procu['Time']>=minv)&(d1_procu['Time']<=maxv)]))\n",
    "    procu_freq.append(len(d2_procu[(d2_procu['Time']>=minv)&(d2_procu['Time']<=maxv)]))\n",
    "    procu_freq.append(len(d3_procu[(d3_procu['Time']>=minv)&(d3_procu['Time']<=maxv)]))\n",
    "    procu_freq.append(len(d4_procu[(d4_procu['Time']>=minv)&(d4_procu['Time']<=maxv)]))\n",
    "    procu_freq.append(len(d5_procu[(d5_procu['Time']>=minv)&(d5_procu['Time']<=maxv)]))\n",
    "\n",
    "    t=(len(dt_procu[(dt_procu['Time']>=minv)&(dt_procu['Time']<=maxv)]))\n",
    "    v1=(len(d1_procu[(d1_procu['Time']>=minv)&(d1_procu['Time']<=maxv)]))\n",
    "    v2=(len(d2_procu[(d2_procu['Time']>=minv)&(d2_procu['Time']<=maxv)]))\n",
    "    v3=(len(d3_procu[(d3_procu['Time']>=minv)&(d3_procu['Time']<=maxv)]))\n",
    "    v4=(len(d4_procu[(d4_procu['Time']>=minv)&(d4_procu['Time']<=maxv)]))\n",
    "    v5=(len(d5_procu[(d5_procu['Time']>=minv)&(d5_procu['Time']<=maxv)])) \n",
    "    \n",
    "    gr1.append(abs(v1-t))\n",
    "    gr2.append(abs(v2-t))\n",
    "    gr3.append(abs(v3-t))\n",
    "    gr4.append(abs(v4-t))\n",
    "    gr5.append(abs(v5-t))\n",
    "    \n",
    "\n",
    "    procu_freq=pd.DataFrame(procu_freq)\n",
    "    procu_freq.columns=[\"value\"]\n",
    "    procu_freq[\"index\"]=[\"template\",\"graph1\",\"graph2\",\"graph3\",\"graph4\",\"graph5\"]\n",
    "    \n",
    "    procu_weight=list()\n",
    "    procu_weight.append(int(sum(dt_procu[(dt_procu['Time']>=minv)&(dt_procu['Time']<=maxv)]['Weight'])))\n",
    "    procu_weight.append(int(sum(d1_procu[(d1_procu['Time']>=minv)&(d1_procu['Time']<=maxv)]['Weight'])))\n",
    "    procu_weight.append(int(sum(d2_procu[(d2_procu['Time']>=minv)&(d2_procu['Time']<=maxv)]['Weight'])))\n",
    "    procu_weight.append(int(sum(d3_procu[(d3_procu['Time']>=minv)&(d3_procu['Time']<=maxv)]['Weight'])))\n",
    "    procu_weight.append(int(sum(d4_procu[(d4_procu['Time']>=minv)&(d4_procu['Time']<=maxv)]['Weight'])))\n",
    "    procu_weight.append(int(sum(d5_procu[(d5_procu['Time']>=minv)&(d5_procu['Time']<=maxv)]['Weight'])))\n",
    "   \n",
    "    t=(int(sum(dt_procu[(dt_procu['Time']>=minv)&(dt_procu['Time']<=maxv)]['Weight'])))\n",
    "    v1=(int(sum(d1_procu[(d1_procu['Time']>=minv)&(d1_procu['Time']<=maxv)]['Weight'])))\n",
    "    v2=(int(sum(d2_procu[(d2_procu['Time']>=minv)&(d2_procu['Time']<=maxv)]['Weight'])))\n",
    "    v3=(int(sum(d3_procu[(d3_procu['Time']>=minv)&(d3_procu['Time']<=maxv)]['Weight'])))\n",
    "    v4=(int(sum(d4_procu[(d4_procu['Time']>=minv)&(d4_procu['Time']<=maxv)]['Weight'])))\n",
    "    v5=(int(sum(d5_procu[(d5_procu['Time']>=minv)&(d5_procu['Time']<=maxv)]['Weight'])))\n",
    "\n",
    "    gr1.append(abs(v1-t))\n",
    "    gr2.append(abs(v2-t))\n",
    "    gr3.append(abs(v3-t))\n",
    "    gr4.append(abs(v4-t))\n",
    "    gr5.append(abs(v5-t))\n",
    "\n",
    "    procu_weight=pd.DataFrame(procu_weight)\n",
    "    procu_weight.columns=[\"value\"]\n",
    "    procu_weight[\"index\"]=[\"template\",\"graph1\",\"graph2\",\"graph3\",\"graph4\",\"graph5\"]\n",
    "  #  print(procu_freq,procu_weight)\n",
    "    dt_travel=dt[dt['eType']==6]\n",
    "   # print(\"dt_procu cut finished \")\n",
    "\n",
    "\n",
    "    d1_travel=d1[d1['eType']==6]\n",
    "   # print(\"d1_procu cut finished \")\n",
    "\n",
    "\n",
    "    d2_travel=d2[d2['eType']==6]\n",
    "   # print(\"d2_procu cut finished \")\n",
    "\n",
    "\n",
    "    d3_travel=d3[d3['eType']==6]\n",
    "   # print(\"d3_procu cut finished \")\n",
    "\n",
    "\n",
    "    d4_travel=d4[d4['eType']==6]\n",
    "   # print(\"d4_procu cut finished \")\n",
    "\n",
    "\n",
    "    d5_travel=d5[d5['eType']==6]\n",
    "   # print(\"d5_procu cut finished \")\n",
    "    \n",
    "#dt_travel, d1_travel ,d2_travel,d3_travel,d4_travel,d5_travel,procu_travel\n",
    "   \n",
    "\n",
    "    procu_dict=[{\"template\":0},{\"graph1\":0},{\"graph2\":0},{\"graph3\":0},{\"graph4\":0},{\"graph5\":0}]\n",
    "\n",
    "    procu_dict=pd.Series(procu_dict) \n",
    "\n",
    "    dt_travel_s_freq,dt_travel_d_freq,ret,dt_s_arr,dt_d_arr=createjsontravel(minv, maxv,dt_travel)\n",
    "    d1_travel_s_freq,d1_travel_d_freq,re1,d1_s_arr,d1_d_arr=createjsontravel(minv, maxv,d1_travel)\n",
    "    d2_travel_s_freq,d2_travel_d_freq,re2,d2_s_arr,d2_d_arr=createjsontravel(minv, maxv,d2_travel)\n",
    "    d3_travel_s_freq,d3_travel_d_freq,re3,d3_s_arr,d3_d_arr=createjsontravel(minv, maxv,d3_travel)\n",
    "    d4_travel_s_freq,d4_travel_d_freq,re4,d4_s_arr,d4_d_arr=createjsontravel(minv, maxv,d4_travel)\n",
    "    d5_travel_s_freq,d5_travel_d_freq,re5,d5_s_arr,d5_d_arr=createjsontravel(minv, maxv,d5_travel)\n",
    "  #  dt_travel_d_freq+\"&&\"+d1_travel_d_freq+\"&&\"+d2_travel_d_freq+\"&&\"+d3_travel_d_freq+\"&&\"+d4_travel_d_freq+\"&&\"+d5_travel_d_freq\n",
    "    result=list()\n",
    "    result.append(ret)\n",
    "    result.append(re1)\n",
    "    result.append(re2)\n",
    "    result.append(re3)\n",
    "    result.append(re4)\n",
    "    result.append(re5)\n",
    "    \n",
    "    gr1.append(abs(re1-ret))\n",
    "    gr2.append(abs(re2-ret))\n",
    "    gr3.append(abs(re3-ret))\n",
    "    gr4.append(abs(re4-ret))\n",
    "    gr5.append(abs(re5-ret))\n",
    "    \n",
    "    result=pd.DataFrame(result)\n",
    "    result.columns=[\"value\"]\n",
    "    result[\"index\"]=[\"template\",\"graph1\",\"graph2\",\"graph3\",\"graph4\",\"graph5\"]\n",
    "    re=list()\n",
    "    re.append(round(stats.wasserstein_distance(dt_s_arr,d1_s_arr),3))\n",
    "    re.append(round(stats.wasserstein_distance(dt_s_arr,d2_s_arr),3))\n",
    "    re.append(round(stats.wasserstein_distance(dt_s_arr,d3_s_arr),3))\n",
    "    re.append(round(stats.wasserstein_distance(dt_s_arr,d4_s_arr),3))\n",
    "    re.append(round(stats.wasserstein_distance(dt_s_arr,d5_s_arr),3))\n",
    "    re.append(round(stats.wasserstein_distance(dt_d_arr,d1_d_arr),3))\n",
    "    re.append(round(stats.wasserstein_distance(dt_d_arr,d2_d_arr),3))\n",
    "    re.append(round(stats.wasserstein_distance(dt_d_arr,d3_d_arr),3))\n",
    "    re.append(round(stats.wasserstein_distance(dt_d_arr,d4_d_arr),3))\n",
    "    re.append(round(stats.wasserstein_distance(dt_d_arr,d5_d_arr),3))\n",
    "    \n",
    "    gr1.append(round(stats.wasserstein_distance(dt_s_arr,d1_s_arr),3))\n",
    "    gr2.append(round(stats.wasserstein_distance(dt_s_arr,d2_s_arr),3))\n",
    "    gr3.append(round(stats.wasserstein_distance(dt_s_arr,d3_s_arr),3))\n",
    "    gr4.append(round(stats.wasserstein_distance(dt_s_arr,d4_s_arr),3))\n",
    "    gr5.append(round(stats.wasserstein_distance(dt_s_arr,d5_s_arr),3))\n",
    "    gr1.append(round(stats.wasserstein_distance(dt_d_arr,d1_d_arr),3))\n",
    "    gr2.append(round(stats.wasserstein_distance(dt_d_arr,d2_d_arr),3))\n",
    "    gr3.append(round(stats.wasserstein_distance(dt_d_arr,d3_d_arr),3))\n",
    "    gr4.append(round(stats.wasserstein_distance(dt_d_arr,d4_d_arr),3))\n",
    "    gr5.append(round(stats.wasserstein_distance(dt_d_arr,d5_d_arr),3))\n",
    "    \n",
    "    \n",
    "    re=pd.Series(re)\n",
    "  #  print(re)\n",
    "   # dt=pd.read_csv(path+'CGCS-Template.csv', delimiter = ',')\n",
    "    dt=dt[dt['eType']==5]\n",
    "  #  print(\"dt reading finished \")\n",
    "\n",
    "   # d1=pd.read_csv(path+'Q1-Graph1.csv', delimiter = ',')\n",
    "    d1=d1[d1['eType']==5]\n",
    "  #  print(\"d1 reading finished \")\n",
    "\n",
    "   # d2=pd.read_csv(path+'Q1-Graph2.csv', delimiter = ',')\n",
    "    d2=d2[d2['eType']==5]\n",
    "\n",
    "  #  print(\"d2 reading finished \")\n",
    "\n",
    "  #  d3=pd.read_csv(path+'Q1-Graph3.csv', delimiter = ',')\n",
    "    d3=d3[d3['eType']==5]\n",
    "  #  print(\"d3 reading finished \")\n",
    "\n",
    "   # d4=pd.read_csv(path+'Q1-Graph4.csv', delimiter = ',')\n",
    "    d4=d4[d4['eType']==5]\n",
    "  #  print(\"d4 reading finished \")\n",
    "\n",
    "   # d5=pd.read_csv(path+'Q1-Graph5.csv', delimiter = ',')\n",
    "    d5=d5[d5['eType']==5]\n",
    "   # print(\"d5 reading finished \")\n",
    "    demoindex=[459381, 466907, 473173, 503218, 503701, 510031, 520660, 523927, 527449, 536346, 537281, 552988, 567195, 571970, 575030, 577992, 580426, 589943, 595298, 595581, 606730, 616315, 620120, 621924, 630626, 632961, 640784, 642329, 644226]\n",
    "    gt=list()\n",
    "    g1=list()\n",
    "    g2=list()\n",
    "    g3=list()\n",
    "    g4=list()\n",
    "    g5=list()\n",
    "    gt1=list()\n",
    "    g11=list()\n",
    "    g21=list()\n",
    "    g31=list()\n",
    "    g41=list()\n",
    "    g51=list()\n",
    "\n",
    "    \n",
    "    i=0\n",
    "    while i<len(demoindex):\n",
    "        gt.append(len(dt[(dt['Source']==demoindex[i])|(dt['Target']==demoindex[i])]))\n",
    "        if((len(dt[(dt['Source']==demoindex[i])|(dt['Target']==demoindex[i])]))!=0):\n",
    "            gt1.append(sum(dt[(dt['Source']==demoindex[i])|(dt['Target']==demoindex[i])]['Weight'])/len(dt[(dt['Source']==demoindex[i])|(dt['Target']==demoindex[i])]))\n",
    "        else:\n",
    "            gt1.append(0)\n",
    "            \n",
    "        g1.append(len(d1[(d1['Source']==demoindex[i])|(d1['Target']==demoindex[i])]))\n",
    "        if((len(d1[(d1['Source']==demoindex[i])|(d1['Target']==demoindex[i])]))!=0):\n",
    "            g11.append(sum(d1[(d1['Source']==demoindex[i])|(d1['Target']==demoindex[i])]['Weight'])/len(d1[(d1['Source']==demoindex[i])|(d1['Target']==demoindex[i])]))\n",
    "        else:\n",
    "            g11.append(0)\n",
    "            \n",
    "        g2.append(len(d2[(d2['Source']==demoindex[i])|(d2['Target']==demoindex[i])]))\n",
    "        if((len(d2[(d2['Source']==demoindex[i])|(d2['Target']==demoindex[i])]))!=0):\n",
    "            g21.append(sum(d2[(d2['Source']==demoindex[i])|(d2['Target']==demoindex[i])]['Weight'])/len(d2[(d2['Source']==demoindex[i])|(d2['Target']==demoindex[i])]))\n",
    "        else:\n",
    "            g21.append(0)\n",
    "            \n",
    "        g3.append(len(d3[(d3['Source']==demoindex[i])|(d3['Target']==demoindex[i])]))\n",
    "        if((len(d3[(d3['Source']==demoindex[i])|(d3['Target']==demoindex[i])]))!=0):\n",
    "            g31.append(sum(d3[(d3['Source']==demoindex[i])|(d3['Target']==demoindex[i])]['Weight'])/len(d3[(d3['Source']==demoindex[i])|(d3['Target']==demoindex[i])]))\n",
    "        else:\n",
    "            g31.append(0)\n",
    "            \n",
    "        g4.append(len(d4[(d4['Source']==demoindex[i])|(d4['Target']==demoindex[i])]))\n",
    "        if((len(d4[(d4['Source']==demoindex[i])|(d4['Target']==demoindex[i])]))!=0):\n",
    "            g41.append(sum(d4[(d4['Source']==demoindex[i])|(d4['Target']==demoindex[i])]['Weight'])/len(d4[(d4['Source']==demoindex[i])|(d4['Target']==demoindex[i])]))\n",
    "        else:\n",
    "            g41.append(0)       \n",
    "            \n",
    "        g5.append(len(d5[(d5['Source']==demoindex[i])|(d5['Target']==demoindex[i])]))\n",
    "        if((len(d5[(d5['Source']==demoindex[i])|(d5['Target']==demoindex[i])]))!=0):\n",
    "            g51.append(sum(d5[(d5['Source']==demoindex[i])|(d5['Target']==demoindex[i])]['Weight'])/len(d5[(d5['Source']==demoindex[i])|(d5['Target']==demoindex[i])]))\n",
    "        else:\n",
    "            g51.append(0)\n",
    "\n",
    "\n",
    "        i+=1\n",
    "    \n",
    "    result=list()\n",
    "    result.append(round(stats.wasserstein_distance(gt,g1),3))\n",
    "    result.append(round(stats.wasserstein_distance(gt,g2),3))\n",
    "    result.append(round(stats.wasserstein_distance(gt,g3),3))\n",
    "    result.append(round(stats.wasserstein_distance(gt,g4),3))\n",
    "    result.append(round(stats.wasserstein_distance(gt,g5),3))\n",
    "    result.append(round(stats.wasserstein_distance(gt1,g11),3))\n",
    "    result.append(round(stats.wasserstein_distance(gt1,g21),3))\n",
    "    result.append(round(stats.wasserstein_distance(gt1,g31),3))\n",
    "    result.append(round(stats.wasserstein_distance(gt1,g41),3))\n",
    "    result.append(round(stats.wasserstein_distance(gt1,g51),3))\n",
    "    \n",
    "    gr1.append(round(stats.wasserstein_distance(gt,g1),3))\n",
    "    gr2.append(round(stats.wasserstein_distance(gt,g2),3))\n",
    "    gr3.append(round(stats.wasserstein_distance(gt,g3),3))\n",
    "    gr4.append(round(stats.wasserstein_distance(gt,g4),3))\n",
    "    gr5.append(round(stats.wasserstein_distance(gt,g5),3))\n",
    "    gr1.append(round(stats.wasserstein_distance(gt1,g11),3))\n",
    "    gr2.append(round(stats.wasserstein_distance(gt1,g21),3))\n",
    "    gr3.append(round(stats.wasserstein_distance(gt1,g31),3))\n",
    "    gr4.append(round(stats.wasserstein_distance(gt1,g41),3))\n",
    "    gr5.append(round(stats.wasserstein_distance(gt1,g51),3))\n",
    "  \n",
    "    gt=pd.DataFrame(gt)\n",
    "    g1=pd.DataFrame(g1)\n",
    "    g2=pd.DataFrame(g2)\n",
    "    g3=pd.DataFrame(g3)\n",
    "    g4=pd.DataFrame(g4)\n",
    "    g5=pd.DataFrame(g5)\n",
    "    gt1=pd.DataFrame(gt1)\n",
    "    g11=pd.DataFrame(g11)\n",
    "    g21=pd.DataFrame(g21)\n",
    "    g31=pd.DataFrame(g31)\n",
    "    g41=pd.DataFrame(g41)\n",
    "    g51=pd.DataFrame(g51)\n",
    "\n",
    "    \n",
    "    gt.columns=[\"value\"]\n",
    "    g1.columns=[\"value\"]\n",
    "    g2.columns=[\"value\"]\n",
    "    g3.columns=[\"value\"]\n",
    "    g4.columns=[\"value\"]\n",
    "    g5.columns=[\"value\"]\n",
    "    gt1.columns=[\"value\"]\n",
    "    g11.columns=[\"value\"]\n",
    "    g21.columns=[\"value\"]\n",
    "    g31.columns=[\"value\"]\n",
    "    g41.columns=[\"value\"]\n",
    "    g51.columns=[\"value\"]\n",
    "    gt[\"index\"]=[\"Water and other public services\" ,\"Electricity\" ,\"Household furnishings\" ,\"Natural gas\" ,\"Miscellaneous\" ,\"Gifts\" ,\"Healthcare\" ,\"Restaurants\" ,\"Alcohol\" ,\"Home maintenance\" ,\"Housekeeping supplies\" ,\"Money income before taxes\" ,\"Personal insurance and pensions\" ,\"Reading\" ,\"Transportation\" ,\"Education\" ,\"Telephone services\" ,\"Lodging away from home\" ,\"Groceries\" ,\"Donations\" ,\"Entertainment\" ,\"Apparel and services\" ,\"Personal taxes\" ,\"Mortgage payments\" ,\"Rented dwellings\" ,\"Personal care products and services\" ,\"Tobacco\" ,\"Household operations\" ,\"Property taxes\"];\n",
    "    g1[\"index\"]=[\"Water and other public services\" ,\"Electricity\" ,\"Household furnishings\" ,\"Natural gas\" ,\"Miscellaneous\" ,\"Gifts\" ,\"Healthcare\" ,\"Restaurants\" ,\"Alcohol\" ,\"Home maintenance\" ,\"Housekeeping supplies\" ,\"Money income before taxes\" ,\"Personal insurance and pensions\" ,\"Reading\" ,\"Transportation\" ,\"Education\" ,\"Telephone services\" ,\"Lodging away from home\" ,\"Groceries\" ,\"Donations\" ,\"Entertainment\" ,\"Apparel and services\" ,\"Personal taxes\" ,\"Mortgage payments\" ,\"Rented dwellings\" ,\"Personal care products and services\" ,\"Tobacco\" ,\"Household operations\" ,\"Property taxes\"];\n",
    "    g2[\"index\"]=[\"Water and other public services\" ,\"Electricity\" ,\"Household furnishings\" ,\"Natural gas\" ,\"Miscellaneous\" ,\"Gifts\" ,\"Healthcare\" ,\"Restaurants\" ,\"Alcohol\" ,\"Home maintenance\" ,\"Housekeeping supplies\" ,\"Money income before taxes\" ,\"Personal insurance and pensions\" ,\"Reading\" ,\"Transportation\" ,\"Education\" ,\"Telephone services\" ,\"Lodging away from home\" ,\"Groceries\" ,\"Donations\" ,\"Entertainment\" ,\"Apparel and services\" ,\"Personal taxes\" ,\"Mortgage payments\" ,\"Rented dwellings\" ,\"Personal care products and services\" ,\"Tobacco\" ,\"Household operations\" ,\"Property taxes\"];\n",
    "    g3[\"index\"]=[\"Water and other public services\" ,\"Electricity\" ,\"Household furnishings\" ,\"Natural gas\" ,\"Miscellaneous\" ,\"Gifts\" ,\"Healthcare\" ,\"Restaurants\" ,\"Alcohol\" ,\"Home maintenance\" ,\"Housekeeping supplies\" ,\"Money income before taxes\" ,\"Personal insurance and pensions\" ,\"Reading\" ,\"Transportation\" ,\"Education\" ,\"Telephone services\" ,\"Lodging away from home\" ,\"Groceries\" ,\"Donations\" ,\"Entertainment\" ,\"Apparel and services\" ,\"Personal taxes\" ,\"Mortgage payments\" ,\"Rented dwellings\" ,\"Personal care products and services\" ,\"Tobacco\" ,\"Household operations\" ,\"Property taxes\"];\n",
    "    g4[\"index\"]=[\"Water and other public services\" ,\"Electricity\" ,\"Household furnishings\" ,\"Natural gas\" ,\"Miscellaneous\" ,\"Gifts\" ,\"Healthcare\" ,\"Restaurants\" ,\"Alcohol\" ,\"Home maintenance\" ,\"Housekeeping supplies\" ,\"Money income before taxes\" ,\"Personal insurance and pensions\" ,\"Reading\" ,\"Transportation\" ,\"Education\" ,\"Telephone services\" ,\"Lodging away from home\" ,\"Groceries\" ,\"Donations\" ,\"Entertainment\" ,\"Apparel and services\" ,\"Personal taxes\" ,\"Mortgage payments\" ,\"Rented dwellings\" ,\"Personal care products and services\" ,\"Tobacco\" ,\"Household operations\" ,\"Property taxes\"];\n",
    "    g5[\"index\"]=[\"Water and other public services\" ,\"Electricity\" ,\"Household furnishings\" ,\"Natural gas\" ,\"Miscellaneous\" ,\"Gifts\" ,\"Healthcare\" ,\"Restaurants\" ,\"Alcohol\" ,\"Home maintenance\" ,\"Housekeeping supplies\" ,\"Money income before taxes\" ,\"Personal insurance and pensions\" ,\"Reading\" ,\"Transportation\" ,\"Education\" ,\"Telephone services\" ,\"Lodging away from home\" ,\"Groceries\" ,\"Donations\" ,\"Entertainment\" ,\"Apparel and services\" ,\"Personal taxes\" ,\"Mortgage payments\" ,\"Rented dwellings\" ,\"Personal care products and services\" ,\"Tobacco\" ,\"Household operations\" ,\"Property taxes\"];\n",
    "    gt1[\"index\"]=[\"Water and other public services\" ,\"Electricity\" ,\"Household furnishings\" ,\"Natural gas\" ,\"Miscellaneous\" ,\"Gifts\" ,\"Healthcare\" ,\"Restaurants\" ,\"Alcohol\" ,\"Home maintenance\" ,\"Housekeeping supplies\" ,\"Money income before taxes\" ,\"Personal insurance and pensions\" ,\"Reading\" ,\"Transportation\" ,\"Education\" ,\"Telephone services\" ,\"Lodging away from home\" ,\"Groceries\" ,\"Donations\" ,\"Entertainment\" ,\"Apparel and services\" ,\"Personal taxes\" ,\"Mortgage payments\" ,\"Rented dwellings\" ,\"Personal care products and services\" ,\"Tobacco\" ,\"Household operations\" ,\"Property taxes\"];\n",
    "    g11[\"index\"]=[\"Water and other public services\" ,\"Electricity\" ,\"Household furnishings\" ,\"Natural gas\" ,\"Miscellaneous\" ,\"Gifts\" ,\"Healthcare\" ,\"Restaurants\" ,\"Alcohol\" ,\"Home maintenance\" ,\"Housekeeping supplies\" ,\"Money income before taxes\" ,\"Personal insurance and pensions\" ,\"Reading\" ,\"Transportation\" ,\"Education\" ,\"Telephone services\" ,\"Lodging away from home\" ,\"Groceries\" ,\"Donations\" ,\"Entertainment\" ,\"Apparel and services\" ,\"Personal taxes\" ,\"Mortgage payments\" ,\"Rented dwellings\" ,\"Personal care products and services\" ,\"Tobacco\" ,\"Household operations\" ,\"Property taxes\"];\n",
    "    g21[\"index\"]=[\"Water and other public services\" ,\"Electricity\" ,\"Household furnishings\" ,\"Natural gas\" ,\"Miscellaneous\" ,\"Gifts\" ,\"Healthcare\" ,\"Restaurants\" ,\"Alcohol\" ,\"Home maintenance\" ,\"Housekeeping supplies\" ,\"Money income before taxes\" ,\"Personal insurance and pensions\" ,\"Reading\" ,\"Transportation\" ,\"Education\" ,\"Telephone services\" ,\"Lodging away from home\" ,\"Groceries\" ,\"Donations\" ,\"Entertainment\" ,\"Apparel and services\" ,\"Personal taxes\" ,\"Mortgage payments\" ,\"Rented dwellings\" ,\"Personal care products and services\" ,\"Tobacco\" ,\"Household operations\" ,\"Property taxes\"];\n",
    "    g31[\"index\"]=[\"Water and other public services\" ,\"Electricity\" ,\"Household furnishings\" ,\"Natural gas\" ,\"Miscellaneous\" ,\"Gifts\" ,\"Healthcare\" ,\"Restaurants\" ,\"Alcohol\" ,\"Home maintenance\" ,\"Housekeeping supplies\" ,\"Money income before taxes\" ,\"Personal insurance and pensions\" ,\"Reading\" ,\"Transportation\" ,\"Education\" ,\"Telephone services\" ,\"Lodging away from home\" ,\"Groceries\" ,\"Donations\" ,\"Entertainment\" ,\"Apparel and services\" ,\"Personal taxes\" ,\"Mortgage payments\" ,\"Rented dwellings\" ,\"Personal care products and services\" ,\"Tobacco\" ,\"Household operations\" ,\"Property taxes\"];\n",
    "    g41[\"index\"]=[\"Water and other public services\" ,\"Electricity\" ,\"Household furnishings\" ,\"Natural gas\" ,\"Miscellaneous\" ,\"Gifts\" ,\"Healthcare\" ,\"Restaurants\" ,\"Alcohol\" ,\"Home maintenance\" ,\"Housekeeping supplies\" ,\"Money income before taxes\" ,\"Personal insurance and pensions\" ,\"Reading\" ,\"Transportation\" ,\"Education\" ,\"Telephone services\" ,\"Lodging away from home\" ,\"Groceries\" ,\"Donations\" ,\"Entertainment\" ,\"Apparel and services\" ,\"Personal taxes\" ,\"Mortgage payments\" ,\"Rented dwellings\" ,\"Personal care products and services\" ,\"Tobacco\" ,\"Household operations\" ,\"Property taxes\"];\n",
    "    g51[\"index\"]=[\"Water and other public services\" ,\"Electricity\" ,\"Household furnishings\" ,\"Natural gas\" ,\"Miscellaneous\" ,\"Gifts\" ,\"Healthcare\" ,\"Restaurants\" ,\"Alcohol\" ,\"Home maintenance\" ,\"Housekeeping supplies\" ,\"Money income before taxes\" ,\"Personal insurance and pensions\" ,\"Reading\" ,\"Transportation\" ,\"Education\" ,\"Telephone services\" ,\"Lodging away from home\" ,\"Groceries\" ,\"Donations\" ,\"Entertainment\" ,\"Apparel and services\" ,\"Personal taxes\" ,\"Mortgage payments\" ,\"Rented dwellings\" ,\"Personal care products and services\" ,\"Tobacco\" ,\"Household operations\" ,\"Property taxes\"];\n",
    "   \n",
    "    result=pd.Series(result)\n",
    "   # print(gr1,gr2,gr3,gr4,gr5)\n",
    "    gr1=pd.DataFrame(gr1)\n",
    "    gr1.columns=[\"graph1\"]\n",
    "    gr1['graph2']=gr2\n",
    "    gr1['graph3']=gr3\n",
    "    gr1['graph4']=gr4\n",
    "    gr1['graph5']=gr5\n",
    "    normalized_df=normalize(gr1)\n",
    "    normalized_df['index']=[\"phone call\", \"phone receive\",\"phone communication\",\"email send\",\"email receive\",\"email communication\",\"procurement freq\",\"procurement weight\",\"demographics freq\",\"demographics weight\",\"source location\",\"target location\",\"trip time\"]\n",
    "    print(normalized_df)\n",
    "    ax=normalized_df.iloc[:,:5]\n",
    "    vg1=0\n",
    "    vg2=0\n",
    "    vg3=0\n",
    "    vg4=0\n",
    "    vg5=0\n",
    "    i=0\n",
    "    while i<(len(ax)):\n",
    "        vmin=ax.loc[i].min()\n",
    "        if(ax.loc[i]['graph1']<=vmin):\n",
    "            vg1+=1\n",
    "            \n",
    "        if(ax.loc[i]['graph2']<=vmin):\n",
    "            vg2+=1\n",
    "            \n",
    "        if(ax.loc[i]['graph3']<=vmin):\n",
    "            vg3+=1\n",
    "            \n",
    "        if(ax.loc[i]['graph4']<=vmin):\n",
    "            vg4+=1\n",
    "            \n",
    "        if(ax.loc[i]['graph5']<=vmin):\n",
    "            vg5+=1\n",
    "       # print(vg1,vg2,vg3,vg4,vg5)\n",
    "        i+=1\n",
    "        \n",
    "    rerate=[vg1,vg2,vg3,vg4,vg5]\n",
    "    rerate=pd.DataFrame(rerate)\n",
    "    rerate.columns=['value']\n",
    "    rerate['index']=['graph1','graph2','graph3','graph4','graph5']\n",
    "    print(rerate)\n",
    "            \n",
    "     \n",
    "        \n",
    "    \n",
    "analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
